{"cells":[{"cell_type":"markdown","metadata":{"id":"ynPXZl3YDmMN"},"source":["# 안녕하세요^^ \n","# AIVLE 미니 프로젝트에 오신 여러분을 환영합니다.\n","* 본 과정에서는 실제 사례와 데이터를 기반으로 문제를 해결하는 전체 과정을 자기 주도형 실습으로 진행해볼 예정입니다.\n","* 앞선 교육과정을 정리하는 마음과 지금까지 배운 내용을 바탕으로 문제 해결을 해볼게요!\n","* 미니 프로젝트를 통한 문제 해결 과정 'A에서 Z까지', 지금부터 시작합니다!"],"id":"ynPXZl3YDmMN"},{"cell_type":"markdown","source":["# __[Study] 4. JSON, XML 등 YOLO와 다른 라벨 포맷 데이터 파싱하기__\n","- Parsing?<br>\n","JSON, XML 등에서 내가 원하는 데이터를 특정 패턴이나 순서로 추출하여 정보로 가공하는 것을 말합니다.<br>\n","'공공 데이터 포탈', 'AI HUB', '서울시 열린데이터' 등 제공하는 데이터들이 보통 .JSON 파일 포맷으로 이미지가 라벨링되어 있으며, <br>\n","라벨링 된 패턴이 데이터마다 상이하여 JSON 파일을 탐색하고 <br>\n","YOLOv5 라벨 데이터 .txt(class_id center_x center_y Dw Dh) 형태로 Convert하는 작업이 필요함. \n","\n","- 실습 파일 4번은 AI HUB 내 <font color=\"red\">공사현장 안전장비 인식 이미지\"</font> 데이터의 일부를 사용할 예정입니다. <br>\n","https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=163"],"metadata":{"id":"Z3kaHY8LGVQc"},"id":"Z3kaHY8LGVQc"},{"cell_type":"markdown","metadata":{"id":"mv9vRNLEDmMP"},"source":["---"],"id":"mv9vRNLEDmMP"},{"cell_type":"markdown","metadata":{"id":"ZPJwlsgmDmMQ"},"source":["## 0. 환경 설정하기"],"id":"ZPJwlsgmDmMQ"},{"cell_type":"markdown","source":["### 1) 구글 드라이브 연결하기"],"metadata":{"id":"xB7iJVzd7eHh"},"id":"xB7iJVzd7eHh"},{"cell_type":"code","source":["# 코랩 사용 시 구글 드라이브 연결\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"B8e3LXc_DmMS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666592515830,"user_tz":-540,"elapsed":18600,"user":{"displayName":"최현우","userId":"12533910615669806298"}},"outputId":"6c974454-42ae-4032-ee0f-27ad8e43af05"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"id":"B8e3LXc_DmMS"},{"cell_type":"markdown","source":["### 2) 경로 확인하기\n","- \"WORK_SPACE\" 에 본인 작업 경로 작성 후 실행(구글 드라이브 최상위에 압축해제 시 그대로 실행. 수정 X).<br>\n","\n","<font color=\"red\">※ 주의. 나머지 경로는 절대 변경하지 마세요.</font>"],"metadata":{"id":"x0gyKH_wt8sH"},"id":"x0gyKH_wt8sH"},{"cell_type":"code","source":["# ROOT_PATH 확인 \n","import os\n","\n","# 구글 드라이브 내 프로젝트 압축해제된 영역 (구글 드라이브 최상위에 압축해제하였을 경우 수정하지 않으셔도 됩니다.)\n","WORK_SPACE = \"\"\n","\n","if os.getcwd() == '/content' :\n","  # 구글 드라이브 사용 시 \n","  ROOT_PATH = \"/content/drive/MyDrive\" + WORK_SPACE + \"/AIVLE_MP_6th\" \n","else :\n","  ROOT_PATH = os.path.abspath('..')\n","\n","# 데이터 경로\n","DATA_PATH = '/content/data'\n","\n","# Train 데이터 셋 경로\n","TRAIN_PATH = DATA_PATH + '/training'\n","TRAIN_IMAGE_PATH = TRAIN_PATH + '/images'\n","TRAIN_LABEL_PATH = TRAIN_PATH + '/labels'\n","\n","# Validation 데이터 셋 경로\n","VALIDATION_PATH = DATA_PATH + '/validation'\n","VALIDATION_IMAGE_PATH = VALIDATION_PATH + '/images'\n","VALIDATION_LABEL_PATH = VALIDATION_PATH + '/labels'\n","\n","# Test 이미지 경로\n","TEST_PATH = DATA_PATH +  \"/test\"\n","TEST_IMAGE_PATH = TEST_PATH + \"/images\"\n","TEST_LABEL_PATH = TEST_PATH + \"/labels\"\n"],"metadata":{"id":"uowqxVvZDmMU","executionInfo":{"status":"ok","timestamp":1666592515831,"user_tz":-540,"elapsed":13,"user":{"displayName":"최현우","userId":"12533910615669806298"}}},"execution_count":2,"outputs":[],"id":"uowqxVvZDmMU"},{"cell_type":"markdown","source":["### 3) YOLOv5 파일 다운로드 및 설치\n","![install](https://github.com/DrKAI/CV/raw/main/UltraLytics_manual/yolov5_install.png)\n","\n","[Install Page](https://github.com/ultralytics/yolov5)"],"metadata":{"id":"HkFHoOtsHi-e"},"id":"HkFHoOtsHi-e"},{"cell_type":"code","source":["# UltraLytics git에서 복사하기\n","!git clone https://github.com/ultralytics/yolov5\n","%cd yolov5\n","!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MLMJi4ZRHibm","executionInfo":{"status":"ok","timestamp":1666592529811,"user_tz":-540,"elapsed":7890,"user":{"displayName":"최현우","userId":"12533910615669806298"}},"outputId":"d3bac48e-f1ad-4358-fc4d-6603582bdb63"},"id":"MLMJi4ZRHibm","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 14379, done.\u001b[K\n","remote: Total 14379 (delta 0), reused 0 (delta 0), pack-reused 14379\u001b[K\n","Receiving objects: 100% (14379/14379), 13.33 MiB | 26.60 MiB/s, done.\n","Resolving deltas: 100% (9950/9950), done.\n","/content/yolov5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.21.6)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (7.1.2)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (2.23.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.7.3)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.12.1+cu113)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.13.1+cu113)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (4.64.1)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (2.9.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (1.3.5)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 24)) (0.11.2)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 41)) (7.9.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 42)) (5.4.8)\n","Collecting thop>=0.1.1\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2022.9.24)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (4.1.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.8.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (57.4.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.17.3)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.0.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.37.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.49.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.4.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 23)) (2022.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.2.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.15.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.9.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.2.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (0.2.0)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 32.6 MB/s \n","\u001b[?25hRequirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (4.8.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (5.1.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (4.4.2)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (2.0.10)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (2.6.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (0.7.5)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->-r requirements.txt (line 41)) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r requirements.txt (line 41)) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->-r requirements.txt (line 41)) (0.7.0)\n","Installing collected packages: jedi, thop\n","Successfully installed jedi-0.18.1 thop-0.1.1.post2209072238\n"]}]},{"cell_type":"markdown","metadata":{"id":"av7r3quaDmMV"},"source":["### 4) 라이브러리 불러오기\n","필요시 추가 라이브러리는 설치해서 사용하세요."],"id":"av7r3quaDmMV"},{"cell_type":"code","execution_count":4,"metadata":{"scrolled":false,"id":"ZYimZcrODmMW","executionInfo":{"status":"ok","timestamp":1666592530255,"user_tz":-540,"elapsed":450,"user":{"displayName":"최현우","userId":"12533910615669806298"}}},"outputs":[],"source":["# 필요 라이브러리 불러오기.\n","import glob\n","import yaml\n","import json\n","from PIL import Image\n","from IPython.display import Image\n","import zipfile\n","import gdown\n","import os\n","\n","from tqdm.auto import tqdm, trange"],"id":"ZYimZcrODmMW"},{"cell_type":"markdown","source":["---"],"metadata":{"id":"c9oKf00KEGKU"},"id":"c9oKf00KEGKU"},{"cell_type":"markdown","source":["## 1. 데이터 불러오기 \n","- 데이터는 AI HUB의 \"공사현장 안전장비 인식 이미지\" 부산 오페라 하우스 신축공사 데이터를 사용합니다.\n","\n","- Train 데이터 셋 경로\n","> TRIAN_IMAGE_PATH = TRAIN_PATH + '/images'<br>\n","> TRAIN_LABEL_PATH = TRAIN_PATH + '/labels'<br>\n","\n","- Validation 데이터 셋 경로\n","> VALIDATION_IMAGE_PATH = VALIDATION_PATH + '/images' <br>\n","> VALIDATION_LABEL_PATH = VALIDATION_PATH + '/labels' <br>\n"],"metadata":{"id":"beVtUNCC_GxR"},"id":"beVtUNCC_GxR"},{"cell_type":"code","source":["%cd \"/content\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eBU9EtmjTMyJ","executionInfo":{"status":"ok","timestamp":1666592533879,"user_tz":-540,"elapsed":4,"user":{"displayName":"최현우","userId":"12533910615669806298"}},"outputId":"94a61a9d-20fc-4c30-baa5-3d5723b3918f"},"id":"eBU9EtmjTMyJ","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["# 아래의 코드를 실행해서 데이터를 불러오세요.\n","\n","def goolge_drive_download (file_id): \n","  google_path = 'https://drive.google.com/uc?id='\n","  output_name = 'download_file.zip'\n","\n","  gdown.download(google_path+file_id,output_name,quiet=False)\n","\n","  zip_file = \"/content/download_file.zip\"\n","\n","  \n","  with zipfile.ZipFile(zip_file) as z:\n","    z.extractall(\"/content\")\n","\n","  os.remove(zip_file) "],"metadata":{"id":"FVlhKmCsRoJI","executionInfo":{"status":"ok","timestamp":1666592537272,"user_tz":-540,"elapsed":2,"user":{"displayName":"최현우","userId":"12533910615669806298"}}},"id":"FVlhKmCsRoJI","execution_count":6,"outputs":[]},{"cell_type":"code","source":["train_file_id = \"1W-WbRJ_R8HtuDL3Z2MukyhcVBlZhv0hm\"\n","goolge_drive_download(train_file_id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eeb1jV7p-VL2","executionInfo":{"status":"ok","timestamp":1666592556546,"user_tz":-540,"elapsed":18887,"user":{"displayName":"최현우","userId":"12533910615669806298"}},"outputId":"88b00228-8ae6-47cc-f869-b165e606b275"},"id":"Eeb1jV7p-VL2","execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1W-WbRJ_R8HtuDL3Z2MukyhcVBlZhv0hm\n","To: /content/download_file.zip\n","100%|██████████| 1.13G/1.13G [00:06<00:00, 163MB/s]\n"]}]},{"cell_type":"markdown","source":["<font color=\"green\">[실습문제]</font> 1. Training/Vlidataion 데이터의 이미지와 라벨 파일들의 경로를 각각 'training_imge_list', 'training_labels_list', 'validation_image_list', 'validation_labels_list' 리스트에 저장하세요.\n","\n"],"metadata":{"id":"RSIkYMN0RCjA"},"id":"RSIkYMN0RCjA"},{"cell_type":"code","source":["# 실습해보세요.\n","training_images_list = glob.glob(TRAIN_IMAGE_PATH + \"/*.jpg\")\n","training_labels_list = glob.glob(TRAIN_LABEL_PATH + \"/*\")"],"metadata":{"id":"tS6xfYw9LaPB","executionInfo":{"status":"ok","timestamp":1666592597791,"user_tz":-540,"elapsed":3,"user":{"displayName":"최현우","userId":"12533910615669806298"}}},"id":"tS6xfYw9LaPB","execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(\"Training Images 개수 : \" + str(len(training_images_list)))\n","print(\"Training Labels 개수 : \" + str(len(training_labels_list)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4CFSic7UVUCo","executionInfo":{"status":"ok","timestamp":1666592598193,"user_tz":-540,"elapsed":3,"user":{"displayName":"최현우","userId":"12533910615669806298"}},"outputId":"f41e19b6-baee-411c-9416-b9f99a58dab2"},"id":"4CFSic7UVUCo","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Images 개수 : 6637\n","Training Labels 개수 : 4105\n"]}]},{"cell_type":"code","source":["validation_images_list = glob.glob(VALIDATION_IMAGE_PATH + \"/*.jpg\")\n","validation_labels_list = glob.glob(VALIDATION_LABEL_PATH + \"/*\")"],"metadata":{"id":"I9ryZUVJPsLT","executionInfo":{"status":"ok","timestamp":1666593778859,"user_tz":-540,"elapsed":495,"user":{"displayName":"최현우","userId":"12533910615669806298"}}},"id":"I9ryZUVJPsLT","execution_count":10,"outputs":[]},{"cell_type":"code","source":["print(\"Validation Images 개수 : \" + str(len(validation_images_list)))\n","print(\"Validation Labels 개수 : \" + str(len(validation_labels_list)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uDtVyO8yP5FN","executionInfo":{"status":"ok","timestamp":1666593779148,"user_tz":-540,"elapsed":3,"user":{"displayName":"최현우","userId":"12533910615669806298"}},"outputId":"1a84d418-6f43-44a0-95d4-5d791f645312"},"id":"uDtVyO8yP5FN","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Images 개수 : 174\n","Validation Labels 개수 : 109\n"]}]},{"cell_type":"code","source":["# 라벨링이 없는 이미지 데이터 삭제  (안해도 무관)\n","\n","def image_data_cleaning(images_list, labels_list):\n","  for image in images_list:\n","    label_file = TRAIN_LABEL_PATH + \"/\" + image.split('/')[-1][:-4] + '.json'\n","    if label_file not in labels_list:\n","      os.remove(image)"],"metadata":{"id":"pMlBbXjfnHjV","executionInfo":{"status":"ok","timestamp":1666593784030,"user_tz":-540,"elapsed":285,"user":{"displayName":"최현우","userId":"12533910615669806298"}}},"id":"pMlBbXjfnHjV","execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## 2. JSON 데이터 Parsing(파싱)하기 \n","> JSON 파일을 Python 객체로 불러올 때 load() 함수를 사용합니다. <br>\n","> Python 객체로 불러오면 데이터는 Dictionary 형태로 저장됩니다."],"metadata":{"id":"q_QeWkVURxwb"},"id":"q_QeWkVURxwb"},{"cell_type":"markdown","source":["<font color=\"green\">[실습문제]</font> 2. training_label_list 에 저장된 첫 번째 .json 파일을 load() 할수를 사용하여 Python 객체로 불러와 json_data 변수에 저장하세요."],"metadata":{"id":"DvwinnepV-vM"},"id":"DvwinnepV-vM"},{"cell_type":"code","source":["training_labels_list[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2a-qZbI5buWI","executionInfo":{"status":"ok","timestamp":1666594006785,"user_tz":-540,"elapsed":379,"user":{"displayName":"최현우","userId":"12533910615669806298"}},"outputId":"77e9dde7-5ed6-44f3-db0e-3064e8777b43"},"id":"2a-qZbI5buWI","execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/data/training/labels/S2-O1301M02123.json',\n"," '/content/data/training/labels/S2-O1301M02564.json',\n"," '/content/data/training/labels/S2-O1301M00787.json',\n"," '/content/data/training/labels/S2-O1301M01486.json',\n"," '/content/data/training/labels/S2-O1301M01090.json']"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# 실습해보세요.\n","with open (training_labels_list[0], \"r\") as f:\n","  json_label = json.load(f)"],"metadata":{"id":"9UBExX8rV8s_","executionInfo":{"status":"ok","timestamp":1666594024772,"user_tz":-540,"elapsed":437,"user":{"displayName":"최현우","userId":"12533910615669806298"}}},"id":"9UBExX8rV8s_","execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["<font color=\"green\">[실습문제]</font> 3. json_data 변수에 저장된 json 파일의 내용과 key 값을 확인해 보고, YOLOv5 labels(.txt) 형태로 변환을 위해 필요한 데이터는 어떤 것이 있는지 확인해 보세요.\n","> dictionary의 키값을 확인할 때는 keys() 메소드를 사용합니다.\n"],"metadata":{"id":"aGzXZ0afWej-"},"id":"aGzXZ0afWej-"},{"cell_type":"code","source":["# 실습해보세요.\n","# pprint 라이브러리를 활용하면 dictionary 형태 출력 시 보기가 편합니다.\n","import pprint\n","\n","pprint.pprint(json_label)\n","\n","print(\"라벨 Key : \" + str(json_label.keys()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"56KLR4bNWdSK","executionInfo":{"status":"ok","timestamp":1666594197273,"user_tz":-540,"elapsed":386,"user":{"displayName":"최현우","userId":"12533910615669806298"}},"outputId":"e5d908a3-0039-48eb-86c0-d4010e2e1c89"},"id":"56KLR4bNWdSK","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["{'annotations': [{'box': [2, 174, 1058, 719],\n","                  'class': '20',\n","                  'data ID': 'S2',\n","                  'flags': 'not occluded, not truncated',\n","                  'middle classification': '03'},\n","                 {'box': [1080, 107, 1133, 172],\n","                  'class': '07',\n","                  'data ID': 'S2',\n","                  'flags': 'not occluded, not truncated',\n","                  'middle classification': '01'},\n","                 {'box': [1036, 166, 1208, 361],\n","                  'class': '01',\n","                  'data ID': 'S2',\n","                  'flags': 'not occluded, not truncated',\n","                  'middle classification': '01'},\n","                 {'class': '04',\n","                  'data ID': 'S2',\n","                  'flags': 'not occluded, not truncated',\n","                  'middle classification': '01',\n","                  'polygon': [[1111, 324],\n","                              [1112, 309],\n","                              [1116, 303],\n","                              [1119, 300],\n","                              [1124, 301],\n","                              [1127, 308],\n","                              [1126, 323],\n","                              [1124, 327],\n","                              [1122, 332],\n","                              [1121, 341],\n","                              [1118, 359],\n","                              [1114, 364],\n","                              [1112, 379],\n","                              [1091, 402],\n","                              [1081, 402],\n","                              [1075, 394],\n","                              [1074, 385],\n","                              [1078, 369],\n","                              [1078, 387],\n","                              [1080, 393],\n","                              [1087, 393],\n","                              [1094, 391],\n","                              [1100, 385],\n","                              [1105, 375],\n","                              [1105, 367],\n","                              [1102, 362],\n","                              [1104, 351],\n","                              [1104, 344],\n","                              [1105, 335],\n","                              [1111, 332]]},\n","                 {'box': [1080, 443, 1143, 573],\n","                  'class': '05',\n","                  'data ID': 'S2',\n","                  'flags': 'occluded, not truncated',\n","                  'middle classification': '01'}],\n"," 'image': {'H_DPI': 96,\n","           'V_DPI': 96,\n","           'bit': '24',\n","           'copyrighter': '미디어그룹사람과숲(컨)',\n","           'date': '20200709',\n","           'filename': 'S2-O1301M02123.jpg',\n","           'location': '13',\n","           'path': 'S2-O1301M00001',\n","           'resolution': [1280, 720]}}\n","라벨 Key : dict_keys(['image', 'annotations'])\n"]}]},{"cell_type":"markdown","source":["<font color=\"green\">[실습문제]</font> 4. json_data 키 값 'Annotations' 안에는 몇 개의 annotation(Bound Box) 정보를 갖고 있는지 확인하고 json_label['annotations']을 <font color=\"red\">annotaions_list</font> 변수에 저장하세요."],"metadata":{"id":"hZKeUXuodBGx"},"id":"hZKeUXuodBGx"},{"cell_type":"code","source":["# 실습해보세요.\n","print(\"Annotation 개수 : \" + str(len(json_label['annotations'])))\n","\n","annotations_list = json_label['annotations']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h-Oj8U4zbMtq","executionInfo":{"status":"ok","timestamp":1666594202900,"user_tz":-540,"elapsed":453,"user":{"displayName":"최현우","userId":"12533910615669806298"}},"outputId":"fe4ff7bf-d3e3-4268-b25f-1f0fa03eba14"},"id":"h-Oj8U4zbMtq","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Annotation 개수 : 5\n"]}]},{"cell_type":"code","source":["annotations_list"],"metadata":{"id":"dbncUKnkgMrB","executionInfo":{"status":"ok","timestamp":1666595039019,"user_tz":-540,"elapsed":299,"user":{"displayName":"최현우","userId":"12533910615669806298"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb6e897d-75cf-4b31-a086-a9d744b28d1a"},"id":"dbncUKnkgMrB","execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'data ID': 'S2',\n","  'middle classification': '03',\n","  'flags': 'not occluded, not truncated',\n","  'box': [2, 174, 1058, 719],\n","  'class': '20'},\n"," {'data ID': 'S2',\n","  'middle classification': '01',\n","  'flags': 'not occluded, not truncated',\n","  'box': [1080, 107, 1133, 172],\n","  'class': '07'},\n"," {'data ID': 'S2',\n","  'middle classification': '01',\n","  'flags': 'not occluded, not truncated',\n","  'box': [1036, 166, 1208, 361],\n","  'class': '01'},\n"," {'polygon': [[1111, 324],\n","   [1112, 309],\n","   [1116, 303],\n","   [1119, 300],\n","   [1124, 301],\n","   [1127, 308],\n","   [1126, 323],\n","   [1124, 327],\n","   [1122, 332],\n","   [1121, 341],\n","   [1118, 359],\n","   [1114, 364],\n","   [1112, 379],\n","   [1091, 402],\n","   [1081, 402],\n","   [1075, 394],\n","   [1074, 385],\n","   [1078, 369],\n","   [1078, 387],\n","   [1080, 393],\n","   [1087, 393],\n","   [1094, 391],\n","   [1100, 385],\n","   [1105, 375],\n","   [1105, 367],\n","   [1102, 362],\n","   [1104, 351],\n","   [1104, 344],\n","   [1105, 335],\n","   [1111, 332]],\n","  'data ID': 'S2',\n","  'middle classification': '01',\n","  'flags': 'not occluded, not truncated',\n","  'class': '04'},\n"," {'data ID': 'S2',\n","  'middle classification': '01',\n","  'flags': 'occluded, not truncated',\n","  'box': [1080, 443, 1143, 573],\n","  'class': '05'}]"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["<font color=\"green\">[실습문제]</font> 5. annotations_list 의 첫 번째 annotation 의 정보 (class, box)를 YOLOv5 좌표 형태('class' 'center_x' 'center_y', 'dw', 'dh') 로 변환하고 출력해 보세요..  \n","> [예시] 출력 예시<br>\n","```\n","\"0 0.11111 0.22222 0.33333 0.44444\"\n","```\n","\n","[참고] \n","> 기존 'box' 좌표 형태는 [x_min, y_min, x_max, y_max] 입니다.<br>\n","> YOLOv5 라벨 데이터의 좌표는 원본 이미지의 가로,세로 길이를 기준으로 정규화 되어 있습니다. <br>\n","> 원본 이미지의 사이즈는 Pillow 라이브러리를 사용하여 가져오세요. <br>\n","<font color=\"red\">Hint.</font> json_label['image'] 안에서 이미지 파일명을 찾을 수 있습니다.<br> "],"metadata":{"id":"QMBTjb5cgNU4"},"id":"QMBTjb5cgNU4"},{"cell_type":"code","source":["# 실습해보세요.\n","x_min, y_min, x_max, y_max =annotations_list[0]['box']\n","\n","# Training 이미지 경로 : TRIAN_IMAGE_PATH\n","img = Image.open(TRAIN_IMAGE_PATH + '/' + json_label['image']['filename'])\n","\n","img_w, img_h = img.size\n","box_w, box_h = [(x_max-x_min), (y_max-y_min)]\n"],"metadata":{"id":"wC2UpORci79s"},"id":"wC2UpORci79s","execution_count":null,"outputs":[]},{"cell_type":"code","source":["yolo_label = []\n","\n","center_x = (x_min+x_max) * 0.5 / img_w\n","center_y = (y_min+y_max) * 0.5 / img_h\n","dw = box_w / img_w\n","dh = box_h / img_h\n","\n","yolo_label.append(str(annotations_list[0]['class'])+\" \"+str(center_x) + \" \" + str(center_y) + \" \" + str(dw) + \" \" + str(dh))\n","print(yolo_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rucZejnMjbLh","executionInfo":{"status":"ok","timestamp":1666055282782,"user_tz":-540,"elapsed":248,"user":{"displayName":"석재민","userId":"11162518966479505622"}},"outputId":"86341999-ee3c-48cb-f895-90f85ecc457a"},"id":"rucZejnMjbLh","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['01 0.1703125 0.6138888888888889 0.0578125 0.1388888888888889']\n"]}]},{"cell_type":"markdown","source":["<font color=\"green\">[실습문제]</font> 6. \"data/training/labels\" 디렉토리 내 .json 파일들을 YOLO labels 데이터 형태인 .txt로 변환하고 TRAIN_CONVERT_PATH  저장하세요. <br>\n","<font color=\"red\">(단, annotation['middle classification'] 의 값이 '01' (중분류 : 안전보호구)인 경우만 yolo_label 리스트에 저장해주세요.) </font>\n","\n","> [예시] yolo_label 리스트 저장 형태<br>\n","```\n","\"0 0.11111 0.22222 0.33333 0.44444\"\n","\"1 0.11111 0.22222 0.33333 0.44444\"\n","\"1 0.11111 0.22222 0.33333 0.44444\"\n","```\n"],"metadata":{"id":"FrGJQXdndeB2"},"id":"FrGJQXdndeB2"},{"cell_type":"code","source":["TRAIN_CONVERT_PATH = TRAIN_PATH + '/convert'\n","\n","if not os.path.exists(TRAIN_CONVERT_PATH):\n","  os.mkdir(TRAIN_CONVERT_PATH)"],"metadata":{"id":"ivCM0LVEfbb5"},"id":"ivCM0LVEfbb5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 실습해보세요.\n","def convert(img_size, box):\n","  img_w = img_size[0]\n","  img_h = img_size[1]\n","\n","  x_min, y_min, x_max, y_max = box\n","\n","  box_w, box_h = [(x_max-x_min), (y_max-y_min)]\n","\n","  center_x = (x_min+x_max) * 0.5 / img_w\n","  center_y = (y_min+y_max) * 0.5 / img_h\n","  \n","  dw = box_w / img_w\n","  dh = box_h / img_h\n"," \n","  return (center_x, center_y, dw, dh)"],"metadata":{"id":"EzQp_z10XBdC"},"id":"EzQp_z10XBdC","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_yolo_label(labels_list, data_path):\n","  convert_path = data_path + \"/convert\"\n","\n","  if not os.path.exists(convert_path):\n","    os.mkdir(convert_path)\n","\n","  for label in tqdm(labels_list, desc=\"CONVERT PROGRESS\"):\n","    with open (label, \"r\") as f:\n","      json_label = json.load(f)\n","\n","    annotations_list = json_label['annotations']\n","    image_file = data_path + \"/images/\" + json_label['image']['filename']  \n","    convert_file = convert_path + \"/\" + json_label['image']['filename'][:-4] + \".txt\"\n","   \n","    image = Image.open(image_file)\n","    image_size = image.size\n","    yolo_label = []\n","    for annotation in annotations_list :\n","      if 'box' in annotation:\n","        if annotation['middle classification'] == '01':\n","          class_id = int(annotation['class'])\n","          box = annotation['box']\n","          (center_x, center_y, dw, dh) = convert(image_size, box)\n","          yolo_label.append(str(class_id) + \" \" + str(center_x) + \" \" + str(center_y) + \" \" + str(dw) + \" \" + str(dh)) \n","    with open(convert_file , 'w') as f:\n","      f.write('\\n'.join(yolo_label) + '\\n')       \n"],"metadata":{"id":"SPo4WXmKaENA"},"id":"SPo4WXmKaENA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["make_yolo_label(training_labels_list, TRAIN_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["c58996a5f38e4aff8a67a5a58e663fea","80a59d971935475982865acd1df637af","7058411b36624a11b96defd6cd74c6ef","ab1a073e08ef4142b661f6f30d14112e","8048b7bc609e444c9375e58c2015e4cf","5fff535583764369854b20b53671b7d7","a27d89df45414cdcba6c50eb12d3aef0","3e6efc3e18aa4a30985fabcbd8c9b16a","58cda704e2b14b4b8e97c39efa8c265b","a7086944fc96454f9a1ffe4a3e9a2ead","09f3c4a1552a4a129910b58b6c280291"]},"id":"x7ZCxNRwazCw","executionInfo":{"status":"ok","timestamp":1666055668373,"user_tz":-540,"elapsed":1764,"user":{"displayName":"석재민","userId":"11162518966479505622"}},"outputId":"a23ae106-547d-40c8-87e7-7ebde59049e0"},"id":"x7ZCxNRwazCw","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["CONVERT PROGRESS:   0%|          | 0/4105 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c58996a5f38e4aff8a67a5a58e663fea"}},"metadata":{}}]},{"cell_type":"markdown","source":["<font color=\"green\">[실습문제]</font> 7. validation_data도 trainging 데이터처럼 json 형태의 labels 데이터를 yolo 학습을 위한 labels(.txt) 형태로 변환하여 저장해 주세요.\n","> 저장경로 : VALIDATION_CONVERT_PATH = VALIDATION_PATH + '/convert'"],"metadata":{"id":"f2fQsYmWrGcI"},"id":"f2fQsYmWrGcI"},{"cell_type":"code","source":["VALIDATION_CONVERT_PATH = VALIDATION_PATH + '/convert'"],"metadata":{"id":"6LjZ0qGvrP9W"},"id":"6LjZ0qGvrP9W","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 실습해보세요.\n","make_yolo_label(validation_labels_list, VALIDATION_PATH)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["76b1cf403f7d448ea4a135bb9d5b42ae","533fc362972c4a4a922f9dc5d14ec74b","f52fffd893744272a6659444347eecf3","16bbfdcc2eec4d7488928332f88cf3d6","9d4912f65b50461796c2a0b5b70eccad","783ba53372c34a6c9bf7a0ecf38317fa","394f5075879543c3aa8b7816530283aa","5061727e30b94b82b46e6e8ec30c2415","565b5faeddc245df867370ddabece885","06a36da1c5194b6e8743fc65730b9b17","d10983af110c415bb8d9bef28b6ebdb2"]},"id":"y66YAK3KqjKW","executionInfo":{"status":"ok","timestamp":1666055693417,"user_tz":-540,"elapsed":254,"user":{"displayName":"석재민","userId":"11162518966479505622"}},"outputId":"a52f2178-1540-42d4-fb30-073eda4abc55"},"id":"y66YAK3KqjKW","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["CONVERT PROGRESS:   0%|          | 0/109 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76b1cf403f7d448ea4a135bb9d5b42ae"}},"metadata":{}}]},{"cell_type":"markdown","source":["<font color=\"green\">[실습문제]</font> 8. training, validation의 labels 폴더 내 데이터를 변형을 완료시킨 데이터(.txt)로 대체해주세요. \n","> [주의] 가급적 기존 json 형태의 데이터는 백업해두고 진행하세요.<br>"],"metadata":{"id":"4Be44tWEbTYr"},"id":"4Be44tWEbTYr"},{"cell_type":"code","source":["BACKUP_PATH = \"/content/backup\""],"metadata":{"id":"IhJ3Tn1oqrDb"},"id":"IhJ3Tn1oqrDb","execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not os.path.exists(BACKUP_PATH):\n","  os.mkdir(BACKUP_PATH)"],"metadata":{"id":"Tj1cxVLLqVaX"},"id":"Tj1cxVLLqVaX","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 실습해보세요.\n","!mv '{TRAIN_LABEL_PATH}' /content/backup/training\n","!mv '{VALIDATION_LABEL_PATH}' /content/backup/validation\n","!mv '{TRAIN_CONVERT_PATH}' '{TRAIN_LABEL_PATH}'\n","!mv '{VALIDATION_CONVERT_PATH}' '{VALIDATION_LABEL_PATH}' "],"metadata":{"id":"0KWL-A3fbSMU"},"id":"0KWL-A3fbSMU","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"ef575059","metadata":{"id":"ef575059"},"source":["---"]},{"cell_type":"markdown","source":["### 3) data.yaml 파일 생성하기"],"metadata":{"id":"CA9K1kNTL8Ed"},"id":"CA9K1kNTL8Ed"},{"cell_type":"markdown","source":["<font color=\"green\">[실습문제]</font> 9. \"data.yaml\" 파일을 생성하고 내 라벨 클래스들과 경로를 입력해주세요.\n","* 데이터 경로 \n","> train : TRAIN_IMAGE_PATH<br>\n","> val : VAL_IMAGE_PATH\n","* 클래스 수 \n","> nc: 9\n","* 클래스 이름 \n","> names: ['None',<br>\n","> &emsp;&emsp;&emsp;&emsp;'안전벨트 착용',<br>\n","> &emsp;&emsp;&emsp;&emsp;'안전벨트 미착용',<br>\n","> &emsp;&emsp;&emsp;&emsp;'안전고리 결착',<br>\n","> &emsp;&emsp;&emsp;&emsp;'안전고리 미결착',<br>\n","> &emsp;&emsp;&emsp;&emsp;'안전화 착용',<br>\n","> &emsp;&emsp;&emsp;&emsp;'안전화 미착용',<br>\n","> &emsp;&emsp;&emsp;&emsp;'안전모 착용',<br>\n","> &emsp;&emsp;&emsp;&emsp;'안전모 미착용',] <br>\n","\n","<font color=\"red\">[Hint]</font> data.yaml 파일은 딕셔너리 형태로 되어 있습니다."],"metadata":{"id":"CwbEk8QZHHmG"},"id":"CwbEk8QZHHmG"},{"cell_type":"code","source":["# 실습해보세요\n","data = {\n","    'train' : TRAIN_IMAGE_PATH,\n","    'val' : VALIDATION_IMAGE_PATH,\n","    'nc' : 9,\n","    'names' : [\n","        'None',\n","        '안전벨트 착용',\n","        '안전벨트 미착용',\n","        '안전고리 결착',\n","        '안전고리 미결착',\n","        '안전화 착용',\n","        '안전화 미착용',\n","        '안전모 착용',\n","        '안전모 미착용',\n","     ]\n","}\n","\n","with open(DATA_PATH + '/data.yaml', 'w') as f:\n","  yaml.dump(data, f, default_flow_style=False, encoding=('utf-8'))\n"],"metadata":{"id":"ItvDXORnHFhw"},"id":"ItvDXORnHFhw","execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(DATA_PATH + '/data.yaml', 'r') as f:\n","  data_check = yaml.load(f, Loader=yaml.FullLoader)"],"metadata":{"id":"ERo9caAQRob9"},"id":"ERo9caAQRob9","execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_check"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"am1Go1n3ZpPi","executionInfo":{"status":"ok","timestamp":1666056091152,"user_tz":-540,"elapsed":230,"user":{"displayName":"석재민","userId":"11162518966479505622"}},"outputId":"0bcc896e-7158-4e20-94f2-c95f1ef5bc91"},"id":"am1Go1n3ZpPi","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'names': ['None',\n","  '안전벨트 착용',\n","  '안전벨트 미착용',\n","  '안전고리 결착',\n","  '안전고리 미결착',\n","  '안전화 착용',\n","  '안전화 미착용',\n","  '안전모 착용',\n","  '안전모 미착용'],\n"," 'nc': 9,\n"," 'train': '/content/data/training/images',\n"," 'val': '/content/data/validation/images'}"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["!cat '/content/data/training/labels/S2-O1301M03550.txt'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ik3JL3i7yx-1","executionInfo":{"status":"ok","timestamp":1666056096810,"user_tz":-540,"elapsed":251,"user":{"displayName":"석재민","userId":"11162518966479505622"}},"outputId":"47846b0a-a021-46b6-9630-aeab495bb133"},"id":"ik3JL3i7yx-1","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["7 0.304296875 0.50625 0.09296875 0.16805555555555557\n","1 0.3171875 0.7965277777777777 0.1484375 0.40694444444444444\n","7 0.771484375 0.41180555555555554 0.21484375 0.4708333333333333\n","1 0.867578125 0.7340277777777777 0.26484375 0.5319444444444444\n","7 0.771484375 0.41180555555555554 0.21484375 0.4708333333333333\n"]}]},{"cell_type":"markdown","source":["## 4. Yolov5 를 이용한 모델 학습\n","> https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data/<br>\n","> ○ [Command] \n","```# 코드로 형식 지정됨\n"," !python train.py --img 640 --epochs 3 --data coco.yaml --weights yolov5n.pt --batch 128 \n","                                                                  yolov5s            64\n","                                                                  yolov5m            40\n","                                                                  yolov5l            24\n","                                                                  yolov5x            16\n","```\n","\n","> ○ [Properties]\n",">> --img: 입력 이미지 크기 <br>\n",">> --batch: 배치 크기 <br>\n",">> --epochs: 학습 epoch 수 <br>\n",">> --data: data.yaml 파일 경로 <br>\n",">> --cfg: 모델 구성 지정 <br>\n",">> --weights: 가중치에 대한 사용자 정의 경로를 지정<br>\n",">> --name: 모델이 저장 될 폴더 이름 <br>\n",">> --nosave: 최종 체크포인트만 저장<br>\n",">> --cache: 더 빠른 학습을 위해 이미지를 캐시<br>\n","\n","> ○ [Select Model]<br>\n","><img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/model_comparison.png\" width=\"640px\">"],"metadata":{"id":"a6-yCQG5ukaR"},"id":"a6-yCQG5ukaR"},{"cell_type":"markdown","source":["<font color=\"green\">[실습문제]</font> 10. Yolov5s(small) 모델을 활용하여 학습하세요.\n","> img size : 416 <br>\n","> batch size : 16 <br>\n","> epochs : 5 <br>\n","> data : /content/data/data.yaml <br>\n","> weights : yolov5s.pt <br>\n","> name : safety_equipment_detection <br>"],"metadata":{"id":"arfZS6b2uqi1"},"id":"arfZS6b2uqi1"},{"cell_type":"code","source":["# 실습해보세요.\n","%cd ./yolov5\n","!python train.py --img 416 --batch 16 --epochs 5 --data /content/data/data.yaml --weights yolov5s.pt --name safety_equipment_detection"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yv7BM968ZKkc","executionInfo":{"status":"ok","timestamp":1666057790829,"user_tz":-540,"elapsed":1585013,"user":{"displayName":"석재민","userId":"11162518966479505622"}},"outputId":"9da2b93a-c0ae-43f7-835a-97acd81d2fbe"},"id":"Yv7BM968ZKkc","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: './yolov5'\n","/content/yolov5\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/data/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=safety_equipment, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v6.2-198-gacff977 Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.Unicode.ttf to /root/.config/Ultralytics/Arial.Unicode.ttf...\n","100% 22.2M/22.2M [00:00<00:00, 37.8MB/s]\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt to yolov5s.pt...\n","100% 14.1M/14.1M [00:00<00:00, 124MB/s] \n","\n","Overriding model.yaml nc=80 with nc=9\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     37758  models.yolo.Detect                      [9, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7043902 parameters, 7043902 gradients, 16.0 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/training/labels' images and labels...4105 found, 2532 missing, 1041 empty, 0 corrupt: 100% 6637/6637 [00:03<00:00, 1980.61it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/training/images/S2-O1301M03550.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/training/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/data/validation/labels' images and labels...109 found, 65 missing, 21 empty, 0 corrupt: 100% 174/174 [00:00<00:00, 653.31it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/validation/labels.cache\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.88 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to runs/train/safety_equipment/labels.jpg... \n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50504 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51204 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48296 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 53944 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52265 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50857 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48120 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44256 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47532 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44208 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54868 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47784 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50504 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51204 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48296 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 53944 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52265 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50857 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48120 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44256 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47532 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44208 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54868 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47784 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","Image sizes 416 train, 416 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/safety_equipment\u001b[0m\n","Starting training for 5 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        0/4      1.66G     0.1213    0.01986    0.06614         45        416:   0% 0/415 [00:01<?, ?it/s]Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","        0/4      1.71G    0.07178    0.02285    0.02503         43        416: 100% 415/415 [05:05<00:00,  1.36it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:04<00:00,  1.27it/s]\n","                   all        174        257      0.808      0.239       0.24      0.106\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        1/4      1.71G    0.05068    0.01867   0.008407         69        416: 100% 415/415 [05:02<00:00,  1.37it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:02<00:00,  2.22it/s]\n","                   all        174        257      0.734      0.362      0.294      0.157\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        2/4      1.71G    0.04329    0.01757   0.007297         51        416: 100% 415/415 [05:10<00:00,  1.34it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:02<00:00,  2.54it/s]\n","                   all        174        257      0.783      0.443      0.328       0.19\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        3/4      1.71G    0.03568    0.01737   0.006232         22        416: 100% 415/415 [04:57<00:00,  1.39it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:02<00:00,  2.38it/s]\n","                   all        174        257      0.794      0.413      0.334      0.206\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        4/4      1.71G    0.03364    0.01707    0.00598         21        416: 100% 415/415 [05:00<00:00,  1.38it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:02<00:00,  2.78it/s]\n","                   all        174        257      0.797      0.443      0.342      0.217\n","\n","5 epochs completed in 0.427 hours.\n","Optimizer stripped from runs/train/safety_equipment/weights/last.pt, 14.3MB\n","Optimizer stripped from runs/train/safety_equipment/weights/best.pt, 14.3MB\n","\n","Validating runs/train/safety_equipment/weights/best.pt...\n","Fusing layers... \n","Model summary: 157 layers, 7034398 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:02<00:00,  2.12it/s]\n","                   all        174        257      0.797      0.443      0.342      0.216\n","               안전벨트 착용        174        120      0.644      0.942      0.715       0.44\n","              안전벨트 미착용        174          3          1          0    0.00798    0.00499\n","                안전화 착용        174         28      0.497       0.75      0.593      0.344\n","               안전화 미착용        174          1          1          0     0.0243     0.0194\n","                안전모 착용        174        103      0.641      0.969      0.695      0.476\n","               안전모 미착용        174          2          1          0     0.0144     0.0103\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50504 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51204 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48296 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 53944 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52265 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50857 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48120 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44256 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47532 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44208 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54868 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47784 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50504 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51204 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48296 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 53944 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52265 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50857 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48120 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44256 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47532 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44208 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54868 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47784 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","Results saved to \u001b[1mruns/train/safety_equipment\u001b[0m\n"]}]},{"cell_type":"markdown","source":["## 5. 모델 성능 확인\n","> Yolo에서는 모델의 성능(정확도)를 Mean Average Precision(mAP)를 통해 확인합니다. <br>\n","mAP가 높을수록 정확하고, 작을수록 부정확합니다. <br>\n","> AP를 계산할 때, precision-recall, IoU 와 연관이 있습니다. <br>\n"],"metadata":{"id":"d3G--l-Xf8ZG"},"id":"d3G--l-Xf8ZG"},{"cell_type":"markdown","source":["<font color=\"green\">[실습문제]</font> 11. model summary를 확인하여 Class 별, 전체 mAP를 확인해 보세요."],"metadata":{"id":"a4XjcMWl8gdE"},"id":"a4XjcMWl8gdE"},{"cell_type":"code","source":["# 실습해보세요."],"metadata":{"id":"KwGI5ljz8dED"},"execution_count":null,"outputs":[],"id":"KwGI5ljz8dED"},{"cell_type":"markdown","source":["\n","```\n","# 코드로 형식 지정됨\n","Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 56/56 [00:18<00:00,  3.05it/s]\n","                   all       1766       6808      0.963      0.608      0.646      0.403\n","                  head       1766       1803      0.942      0.896      0.944       0.59\n","                helmet       1766       4863      0.948      0.927      0.971      0.606\n","                person       1766        142          1          0     0.0243     0.0136\n","```\n","\n"],"metadata":{"id":"WjvkhTtT8SAr"},"id":"WjvkhTtT8SAr"},{"cell_type":"markdown","source":["## 6. Test 데이터 추론하기 \n","* 해당 결과는 runs/detect/exp/ 위치에 저장됩니다.\n","> ○ [Command] \n","``` # 코드로 형식 지정됨\n","!python detect.py --source 0  # webcam\n","                           img.jpg  # image\n","                           vid.mp4  # video\n","                           screen  # screenshot\n","                           path/  # directory\n","                           'path/*.jpg'  # glob\n","                           'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n","                           'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n","```\n","> ○ [Properties] \n",">> -- source : test 데이터(이미지, 영상 파일 혹은 폴더) 경로 <br>\n",">> -- weights : 학습이 완료된 weight 파일 경로 (pt 형식) <br>\n",">> -- conf : conf_threshold 값 (0 ~ 1 사이의 값)\n"],"metadata":{"id":"iCKM0MCGe0NQ"},"id":"iCKM0MCGe0NQ"},{"cell_type":"markdown","source":["* TEST 데이터 다운로드하기(아래의 코드를 실행하세요)\n"],"metadata":{"id":"bVEutMdIG65a"},"id":"bVEutMdIG65a"},{"cell_type":"code","source":["# 현재 디렉토리 확인\n","%pwd\n","%cd /content"],"metadata":{"id":"Kgxu2agF2cAr"},"execution_count":null,"outputs":[],"id":"Kgxu2agF2cAr"},{"cell_type":"code","source":["!pip install gdown"],"metadata":{"id":"JnEqBQ8C2MeH"},"execution_count":null,"outputs":[],"id":"JnEqBQ8C2MeH"},{"cell_type":"code","source":["import gdown\n","import zipfile"],"metadata":{"id":"AcNkxlOD2SYd"},"execution_count":null,"outputs":[],"id":"AcNkxlOD2SYd"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddT3ob9cBZX1"},"outputs":[],"source":["test_file_id = \"14PsLrMhL2v7n3dYjv2JOFWF6iIUFYhyQ\"\n","\n","def goolge_drive_download (file_id): \n","  google_path = 'https://drive.google.com/uc?id='\n","  output_name = 'download_file.zip'\n","\n","  gdown.download(google_path+file_id,output_name,quiet=False)\n","\n","  zip_file = \"/content/download_file.zip\"\n","\n","  \n","  with zipfile.ZipFile(zip_file) as z:\n","    z.extractall(\"/content\")\n","\n","  os.remove(zip_file) "],"id":"ddT3ob9cBZX1"},{"cell_type":"code","source":["goolge_drive_download(test_file_id)"],"metadata":{"id":"3G3jHfuW2XnO"},"execution_count":null,"outputs":[],"id":"3G3jHfuW2XnO"},{"cell_type":"markdown","source":["<font color=\"green\">[실습문제]</font> 12-1. 이미지를 소스로 한 객체 검출하기 \n","> 경로 \"TEST_IMAGE_PATH\" 의 이미지 파일들의 객체를 검출해 보세요.  \n","> [조건] \n","> ① img size : 416, ② IOU Threshold : 0.5, ③ 모델 weights : best.pt"],"metadata":{"id":"Pf6GmQ9SvDbV"},"id":"Pf6GmQ9SvDbV"},{"cell_type":"code","source":["# 실습해보세요\n","%cd /content/yolov5\n","!python detect.py --source '{TEST_IMAGE_PATH}' --weights /content/yolov5/runs/train/safety_equipment/weights/best.pt --img 416 --conf 0.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pr4f_N3BZL5v","executionInfo":{"status":"ok","timestamp":1666058526167,"user_tz":-540,"elapsed":8205,"user":{"displayName":"석재민","userId":"11162518966479505622"}},"outputId":"1ef743df-9365-4e88-8840-35c3b401884e"},"id":"pr4f_N3BZL5v","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n","\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/safety_equipment/weights/best.pt'], source=/content/data/test/images/, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v6.2-198-gacff977 Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","Model summary: 157 layers, 7034398 parameters, 0 gradients, 15.8 GFLOPs\n","image 1/12 /content/data/test/images/test_image_01.jpg: 256x416 3 안전벨트 착용s, 5 안전모 착용s, 11.5ms\n","image 2/12 /content/data/test/images/test_image_02.jpg: 256x416 (no detections), 8.4ms\n","image 3/12 /content/data/test/images/test_image_03.jpg: 256x416 3 안전벨트 착용s, 2 안전화 착용s, 2 안전모 착용s, 7.3ms\n","image 4/12 /content/data/test/images/test_image_04.jpg: 256x416 1 안전벨트 착용, 7.8ms\n","image 5/12 /content/data/test/images/test_image_05.jpg: 256x416 3 안전벨트 착용s, 1 안전화 착용, 2 안전모 착용s, 8.1ms\n","image 6/12 /content/data/test/images/test_image_06.jpg: 256x416 1 안전벨트 착용, 1 안전화 착용, 1 안전모 착용, 8.0ms\n","image 7/12 /content/data/test/images/test_image_07.jpg: 256x416 1 안전벨트 착용, 1 안전화 착용, 1 안전모 착용, 8.2ms\n","image 8/12 /content/data/test/images/test_image_08.jpg: 256x416 1 안전벨트 착용, 1 안전모 착용, 8.8ms\n","image 9/12 /content/data/test/images/test_image_09.jpg: 256x416 2 안전벨트 착용s, 2 안전모 착용s, 9.9ms\n","image 10/12 /content/data/test/images/test_image_10.jpg: 256x416 1 안전벨트 착용, 1 안전모 착용, 8.6ms\n","image 11/12 /content/data/test/images/test_image_11.jpg: 256x416 2 안전벨트 착용s, 2 안전모 착용s, 7.9ms\n","image 12/12 /content/data/test/images/test_image_12.jpg: 256x416 3 안전벨트 착용s, 2 안전모 착용s, 12.5ms\n","Speed: 0.5ms pre-process, 8.9ms inference, 1.0ms NMS per image at shape (1, 3, 416, 416)\n","Results saved to \u001b[1mruns/detect/exp4\u001b[0m\n"]}]},{"cell_type":"markdown","source":["<font color=\"green\">[실습문제]</font> 12-2. detect가 완료된 이미지를 확인해 보세요.\n"],"metadata":{"id":"wBAqWUHHvh3F"},"id":"wBAqWUHHvh3F"},{"cell_type":"code","source":["# 필요 라이브러리 불러오기\n","from PIL import Image               # to load images\n","from IPython.display import display # to display images"],"metadata":{"id":"vfodzc4rUXAJ"},"id":"vfodzc4rUXAJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 실습해보세요.\n","detect_image_path = \"/content/yolov5/runs/detect/exp\"  #detect가 완료된 파일의 경로\n","\n","for i in glob.glob(detect_image_path + '/*.jpg'):\n","  img = Image.open(i)\n","  img_resize = img.resize((640, 360))\n","  display(img_resize)\n","  print('\\n')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1fFjXtYfroz1LcUhwanOfG5MH3RTu9kuE"},"id":"Bu-rhcX0gaMY","executionInfo":{"status":"ok","timestamp":1666058531258,"user_tz":-540,"elapsed":3982,"user":{"displayName":"석재민","userId":"11162518966479505622"}},"outputId":"6f8ef0d2-a857-42ec-9a88-e5549bffadc1"},"id":"Bu-rhcX0gaMY","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6VHAuI2I-Rb"},"outputs":[],"source":["# 필요 라이브러리 불러오기\n","from PIL import Image               # to load images\n","from IPython.display import display # to display images"],"id":"c6VHAuI2I-Rb"}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c58996a5f38e4aff8a67a5a58e663fea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80a59d971935475982865acd1df637af","IPY_MODEL_7058411b36624a11b96defd6cd74c6ef","IPY_MODEL_ab1a073e08ef4142b661f6f30d14112e"],"layout":"IPY_MODEL_8048b7bc609e444c9375e58c2015e4cf"}},"80a59d971935475982865acd1df637af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fff535583764369854b20b53671b7d7","placeholder":"​","style":"IPY_MODEL_a27d89df45414cdcba6c50eb12d3aef0","value":"CONVERT PROGRESS: 100%"}},"7058411b36624a11b96defd6cd74c6ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e6efc3e18aa4a30985fabcbd8c9b16a","max":4105,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58cda704e2b14b4b8e97c39efa8c265b","value":4105}},"ab1a073e08ef4142b661f6f30d14112e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7086944fc96454f9a1ffe4a3e9a2ead","placeholder":"​","style":"IPY_MODEL_09f3c4a1552a4a129910b58b6c280291","value":" 4105/4105 [00:01&lt;00:00, 3172.36it/s]"}},"8048b7bc609e444c9375e58c2015e4cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fff535583764369854b20b53671b7d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a27d89df45414cdcba6c50eb12d3aef0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e6efc3e18aa4a30985fabcbd8c9b16a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58cda704e2b14b4b8e97c39efa8c265b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7086944fc96454f9a1ffe4a3e9a2ead":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09f3c4a1552a4a129910b58b6c280291":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76b1cf403f7d448ea4a135bb9d5b42ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_533fc362972c4a4a922f9dc5d14ec74b","IPY_MODEL_f52fffd893744272a6659444347eecf3","IPY_MODEL_16bbfdcc2eec4d7488928332f88cf3d6"],"layout":"IPY_MODEL_9d4912f65b50461796c2a0b5b70eccad"}},"533fc362972c4a4a922f9dc5d14ec74b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_783ba53372c34a6c9bf7a0ecf38317fa","placeholder":"​","style":"IPY_MODEL_394f5075879543c3aa8b7816530283aa","value":"CONVERT PROGRESS: 100%"}},"f52fffd893744272a6659444347eecf3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5061727e30b94b82b46e6e8ec30c2415","max":109,"min":0,"orientation":"horizontal","style":"IPY_MODEL_565b5faeddc245df867370ddabece885","value":109}},"16bbfdcc2eec4d7488928332f88cf3d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06a36da1c5194b6e8743fc65730b9b17","placeholder":"​","style":"IPY_MODEL_d10983af110c415bb8d9bef28b6ebdb2","value":" 109/109 [00:00&lt;00:00, 1263.74it/s]"}},"9d4912f65b50461796c2a0b5b70eccad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"783ba53372c34a6c9bf7a0ecf38317fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"394f5075879543c3aa8b7816530283aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5061727e30b94b82b46e6e8ec30c2415":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"565b5faeddc245df867370ddabece885":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"06a36da1c5194b6e8743fc65730b9b17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d10983af110c415bb8d9bef28b6ebdb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}